{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Data with Pandas\n",
    "## CHAPTER 1: Extracting and transforming data\n",
    "### iloc and loc in pandas\n",
    "\n",
    "![loc and iloc](Pandas-selections-and-indexing.png)\n",
    "\n",
    "#### iloc\n",
    "`iloc` is not usually used unless we want to access the first and last column as `df.iloc[0] and df.iloc[-1]`\n",
    "\n",
    "_Remarks:_\n",
    "\n",
    "1. Note that .iloc returns a Pandas Series when one row is selected, and a Pandas DataFrame when multiple rows are selected, or if any column in full is selected. To counter this, pass a single-valued list if you require DataFrame output.\n",
    "2. When using .loc, or .iloc, you can control the output format by passing lists or single values to the selectors.\n",
    "3. When using .loc, or .iloc, you can control the output format by passing lists or single values to the selectors.\n",
    "4. When selecting multiple columns or multiple rows in this manner, remember that in your selection e.g.[1:5], the rows/columns selected will run from the first number to one minus the second number. e.g. [1:5] will go 1,2,3,4., [x,y] goes from x to y-1.\n",
    "\n",
    "#### loc\n",
    "`loc` is more popular when extracting data than `iloc`.\n",
    "\n",
    "##### Label-based / Index-based indexing using .loc\n",
    "Examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with index values 'Andrade' and 'Veness', with all columns between 'city' and 'email'\n",
    "data.loc[['Andrade', 'Veness'], 'city':'email']\n",
    "# Select same rows, with just 'first_name', 'address' and 'city' columns\n",
    "data.loc['Andrade':'Veness', ['first_name', 'address', 'city']]\n",
    " \n",
    "# Change the index to be based on the 'id' column\n",
    "data.set_index('id', inplace=True)\n",
    "# select the row with 'id' = 487\n",
    "data.loc[487]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boolean / Logical indexing using .loc\n",
    "Note that there are two output modes that .loc will return when we execute: \n",
    "![.loc output examples](loc_indexer_returns_series_or_dataframe.png)\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with first name Antonio, # and all columns between 'city' and 'email'\n",
    "data.loc[data['first_name'] == 'Antonio', 'city':'email']\n",
    " \n",
    "# Select rows where the email column ends with 'hotmail.com', include all columns\n",
    "data.loc[data['email'].str.endswith(\"hotmail.com\")]   \n",
    " \n",
    "# Select rows with last_name equal to some values, all columns\n",
    "data.loc[data['first_name'].isin(['France', 'Tyisha', 'Eric'])]   \n",
    "       \n",
    "# Select rows with first name Antonio AND hotmail email addresses\n",
    "data.loc[data['email'].str.endswith(\"gmail.com\") & (data['first_name'] == 'Antonio')] \n",
    " \n",
    "# select rows with id column between 100 and 200, and just return 'postal' and 'web' columns\n",
    "data.loc[(data['id'] > 100) & (data['id'] <= 200), ['postal', 'web']] \n",
    " \n",
    "# A lambda function that yields True/False values can also be used.\n",
    "# Select rows where the company name has 4 words in it.\n",
    "data.loc[data['company_name'].apply(lambda x: len(x.split(' ')) == 4)] \n",
    " \n",
    "# Selections can be achieved outside of the main .loc for clarity:\n",
    "# Form a separate variable with your selections:\n",
    "idx = data['company_name'].apply(lambda x: len(x.split(' ')) == 4)\n",
    "# Select only the True values in 'idx' and only the 3 columns specified:\n",
    "data.loc[idx, ['email', 'first_name', 'company']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ix - alternative way for .loc and .iloc\n",
    "The `ix[] indexe`r is a hybrid of `.loc` and `.iloc`. Generally, ix is label based and acts just as the `.loc` indexer. However, `.ix` also supports integer type selections (as in `.iloc`) where passed an integer. __This only works where the index of the DataFrame is not integer based__. `ix` will accept any of the inputs of `.loc` and `.iloc`.\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ix indexing works just the same as .loc when passed strings\n",
    "data.ix[['Andrade']] == data.loc[['Andrade']]\n",
    "# ix indexing works the same as .iloc when passed integers.\n",
    "data.ix[[33]] == data.iloc[[33]]\n",
    " \n",
    "# ix only works in both modes when the index of the DataFrame is NOT an integer itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional and labeled indexing\n",
    "Given a pair of label-based indices, sometimes it's necessary to find the corresponding positions. In this exercise, you will use the Pennsylvania election results again. The DataFrame is provided for you as election.\n",
    "\n",
    "Find x and y such that e`lection.iloc[x, y] == election.loc['Bedford', 'winner']`. That is, what is the row position of `'Bedford'`, and the column position of 'winner'? Remember that the first position in Python is 0, not 1!\n",
    "\n",
    "To answer this question, first explore the DataFrame using `election.head()` in the IPython Shell and inspect it with your eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the row position of election.loc['Bedford']: x\n",
    "election.index\n",
    "x = election.index.get_loc('Bedford')\n",
    "\n",
    "# Assign the column position of election['winner']: y\n",
    "y = election.columns.get_loc('winner')\n",
    "\n",
    "# Print the boolean equivalence\n",
    "print(election.iloc[x, y] == election.loc['Bedford', 'winner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and column rearrangement\n",
    "There are circumstances in which it's useful to modify the order of your DataFrame columns. We do that now by extracting just two columns from the Pennsylvania election results DataFrame.\n",
    "\n",
    "Your job is to read the CSV file and set the index to `'county'`. You'll then assign a new DataFrame by selecting the list of columns `['winner', 'total', 'voters']`. The CSV file is provided to you in the variable filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in filename and set the index: election\n",
    "election = pd.read_csv(filename, index_col='county')\n",
    "\n",
    "# Create a separate dataframe with the columns ['winner', 'total', 'voters']: results\n",
    "results = election[['winner', 'total', 'voters']]\n",
    "\n",
    "# Print the output of results.head()\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing rows\n",
    "The Pennsylvania US election results data set that you have been using so far is ordered by county name. This means that county names can be sliced alphabetically. In this exercise, you're going to perform slicing on the county names of the election DataFrame from the previous exercises, which has been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the row labels 'Perry' to 'Potter': p_counties\n",
    "p_counties = election.loc['Perry':'Potter']\n",
    "\n",
    "# Print the p_counties DataFrame\n",
    "print(p_counties)\n",
    "\n",
    "# Slice the row labels 'Potter' to 'Perry' in reverse order: p_counties_rev\n",
    "p_counties_rev = election.loc['Potter':'Perry':-1]\n",
    "\n",
    "# Print the p_counties_rev DataFrame\n",
    "print(p_counties_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing columns\n",
    "Similar to row slicing, columns can be sliced by value. In this exercise, your job is to slice column names from the Pennsylvania election results DataFrame using `.loc[]`.\n",
    "\n",
    "It has been pre-loaded for you as election, with the index set to `'county'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the columns from the starting column to 'Obama': left_columns\n",
    "left_columns = election.loc[:,:'Obama']\n",
    "\n",
    "# Print the output of left_columns.head()\n",
    "print(left_columns.head())\n",
    "\n",
    "# Slice the columns from 'Obama' to 'winner': middle_columns\n",
    "middle_columns = election.loc[:,'Obama':'winner']\n",
    "\n",
    "# Print the output of middle_columns.head()\n",
    "print(middle_columns.head())\n",
    "\n",
    "# Slice the columns from 'Romney' to the end: 'right_columns'\n",
    "right_columns = election.loc[:,'Romney':]\n",
    "\n",
    "# Print the output of right_columns.head()\n",
    "print(right_columns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subselecting DataFrames with lists\n",
    "You can use lists to select specific row and column labels with the `.loc[]` accessor. In this exercise, your job is to select the counties `['Philadelphia', 'Centre', 'Fulton']` and the columns `['winner','Obama','Romney']` from the election DataFrame, which has been pre-loaded for you with the index set to `'county'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of row labels: rows\n",
    "rows = ['Philadelphia', 'Centre', 'Fulton']\n",
    "\n",
    "# Create the list of column labels: cols\n",
    "cols = ['winner', 'Obama', 'Romney']\n",
    "\n",
    "# Create the new DataFrame: three_counties\n",
    "three_counties = election.loc[rows, cols]\n",
    "\n",
    "# Print the three_counties DataFrame\n",
    "print(three_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding data\n",
    "In this exercise, we have provided the Pennsylvania election results and included a column called `'turnout'` that contains the percentage of voter turnout per county. Your job is to prepare a boolean array to select all of the rows and columns where voter turnout exceeded `70%`.\n",
    "\n",
    "As before, the DataFrame is available to you as election with the index set to `'county'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boolean array: high_turnout\n",
    "high_turnout = election['turnout']>70\n",
    "\n",
    "# Filter the election DataFrame with the high_turnout array: high_turnout_df\n",
    "high_turnout_df = election[high_turnout]\n",
    "\n",
    "# Print the high_turnout_results DataFrame\n",
    "print(high_turnout_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering columns using other columns\n",
    "The election results DataFrame has a column labeled `'margin'` which expresses the number of extra votes the winner received over the losing candidate. This number is given as a percentage of the total votes cast. It is reasonable to assume that in counties where this margin was less than `1%`, the results would be too-close-to-call.\n",
    "\n",
    "Your job is to use boolean selection to filter the rows where the margin was less than 1. You'll then convert these rows of the `'winner'` column to np.nan to indicate that these results are too close to declare a winner.\n",
    "\n",
    "The DataFrame has been pre-loaded for you as election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create the boolean array: too_close\n",
    "too_close = election['margin']<1\n",
    "\n",
    "# Assign np.nan to the 'winner' column where the results were too close to call\n",
    "election[too_close] = np.nan\n",
    "\n",
    "# Print the output of election.info()\n",
    "print(election.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering using NaNs\n",
    "In certain scenarios, it may be necessary to remove rows and columns with missing data from a DataFrame. The `.dropna()` method is used to perform this action. You'll now practice using this method on a dataset obtained from Vanderbilt University, which consists of data from passengers on the Titanic.\n",
    "\n",
    "The DataFrame has been pre-loaded for you as titanic. Explore it in the IPython Shell and you will note that there are many NaNs. You will focus specifically on the 'age' and 'cabin' columns in this exercise. Your job is to use `.dropna()` to remove rows where any of these two columns contains missing data and rows where all of these two columns contain missing data.\n",
    "\n",
    "You'll also use the `.shape` attribute, which returns the number of rows and columns in a tuple from a DataFrame, or the number of rows from a Series, to see the effect of dropping missing values from a DataFrame.\n",
    "\n",
    "Finally, you'll use the thresh= keyword argument to drop columns from the full dataset that have less than 1000 non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'age' and 'cabin' columns: df\n",
    "df = titanic.loc[:, ['age', 'cabin']]\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Drop rows in df with how='any' and print the shape\n",
    "print(df.dropna(how='any').shape)\n",
    "\n",
    "# Drop rows in df with how='all' and print the shape\n",
    "print(df.dropna(how='all').shape)\n",
    "\n",
    "# Drop columns in titanic with less than 1000 non-missing values\n",
    "print(titanic.dropna(thresh=1000, axis='columns').info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using apply() to transform a column\n",
    "The `.apply()` method can be used on a pandas DataFrame to apply an arbitrary Python function to every element. In this exercise you'll take daily weather data in Pittsburgh in `2013` obtained from Weather Underground.\n",
    "\n",
    "A function to convert degrees Fahrenheit to degrees Celsius has been written for you. Your job is to use the .apply() method to perform this conversion on the `'Mean TemperatureF'` and `'Mean Dew PointF'` columns of the weather DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to convert degrees Fahrenheit to degrees Celsius: to_celsius\n",
    "def to_celsius(F):\n",
    "    return 5/9*(F - 32)\n",
    "\n",
    "# Apply the function over 'Mean TemperatureF' and 'Mean Dew PointF': df_celsius\n",
    "df_celsius = weather[['Mean TemperatureF','Mean Dew PointF']].apply(to_celsius)\n",
    "\n",
    "# Reassign the column labels of df_celsius\n",
    "df_celsius.columns = ['Mean TemperatureC', 'Mean Dew PointC']\n",
    "\n",
    "# Print the output of df_celsius.head()\n",
    "print(df_celsius.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .map() with a dictionary\n",
    "The .map() method is used to transform values according to a Python dictionary look-up. In this exercise you'll practice this method while returning to working with the election DataFrame, which has been pre-loaded for you.\n",
    "\n",
    "Your job is to use a dictionary to map the values `'Obama'` and `'Romney'` in the `'winner'` column to the values `'blue'` and `'red'`, and assign the output to the new column `'color'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary: red_vs_blue\n",
    "red_vs_blue = {'Obama':'blue', 'Romney':'red'}\n",
    "\n",
    "# Use the dictionary to map the 'winner' column to the new column: election['color']\n",
    "election['color'] = (election['winner']).map(red_vs_blue)\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using vectorized functions\n",
    "When performance is paramount, you should avoid using `.apply()` and `.map()` because those constructs perform Python for-loops over the data stored in a pandas Series or DataFrame. By using vectorized functions instead, you can loop over the data at the same speed as compiled code (C, Fortran, etc.)! NumPy, SciPy and pandas come with a variety of vectorized functions (called Universal Functions or UFuncs in NumPy).\n",
    "\n",
    "You can even write your own vectorized functions, but for now we will focus on the ones distributed by NumPy and pandas.\n",
    "\n",
    "In this exercise you're going to import the zscore function from scipy.stats and use it to compute the deviation in voter turnout in Pennsylvania from the mean in fractions of the standard deviation. In statistics, the `z-score` is the number of standard deviations by which an observation is above the mean - so if it is negative, it means the observation is below the mean.\n",
    "\n",
    "Instead of using `.apply()` as you did in the earlier exercises, the zscore UFunc will take a pandas Series as input and return a NumPy array. You will then assign the values of the NumPy array to a new column in the DataFrame. You will be working with the election DataFrame - it has been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import zscore from scipy.stats\n",
    "from scipy.stats import zscore \n",
    "\n",
    "# Call zscore with election['turnout'] as input: turnout_zscore\n",
    "turnout_zscore = zscore(election['turnout'])\n",
    "\n",
    "# Print the type of turnout_zscore\n",
    "print(type(turnout_zscore))\n",
    "\n",
    "# Assign turnout_zscore to a new column: election['turnout_zscore']\n",
    "election['turnout_zscore']=turnout_zscore\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 2: Advanced indexing\n",
    "### Changing index of a DataFrame\n",
    "As you saw in the previous exercise, indexes are immutable objects. This means that if you want to change or modify the index in a DataFrame, then you need to change the whole index. You will do this now, using a list comprehension to create the new index.\n",
    "\n",
    "A list comprehension is a succinct way to generate a list in one line. For example, the following list comprehension generates a list that contains the cubes of all numbers from 0 to 9: `cubes = [i**3 for i in range(10)]`. This is equivalent to the following code:\n",
    "\n",
    "```python\n",
    "cubes = []\n",
    "for i in range(10):\n",
    "    cubes.append(i**3)\n",
    "```\n",
    "Before getting started, print the sales DataFrame in the IPython Shell and verify that the index is given by month abbreviations containing lowercase characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of new indexes: new_idx\n",
    "new_idx = [i.upper() for i in sales.index]\n",
    "\n",
    "# Assign new_idx to sales.index\n",
    "sales.index = new_idx\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing index name labels\n",
    "Notice that in the previous exercise, the index was not labeled with a name. In this exercise, you will set its name to 'MONTHS'.\n",
    "\n",
    "Similarly, if all the columns are related in some way, you can provide a label for the set of columns.\n",
    "\n",
    "To get started, print the sales DataFrame in the IPython Shell and verify that the index has no name, only its data (the month names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the string 'MONTHS' to sales.index.name\n",
    "sales.index.name = 'MONTHS'\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Assign the string 'PRODUCTS' to sales.columns.name \n",
    "sales.columns.name = 'PRODUCTS'\n",
    "\n",
    "# Print the sales dataframe again\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an index, then a DataFrame\n",
    "You can also build the DataFrame and index independently, and then put them together. If you take this route, be careful, as any mistakes in generating the DataFrame or the index can cause the data and the index to be aligned incorrectly.\n",
    "\n",
    "In this exercise, the `sales` DataFrame has been provided for you without the month index. Your job is to build this index separately and then assign it to the sales DataFrame. Before getting started, print the sales DataFrame in the IPython Shell and note that it's missing the month information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list of months: months\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\n",
    "\n",
    "# Assign months to sales.index\n",
    "sales.index=months\n",
    "\n",
    "# Print the modified sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data with a MultiIndex\n",
    "In the video, Dhavide explained the concept of a `hierarchical index`, or a `MultiIndex`. You will now practice working with these types of indexes.\n",
    "\n",
    "The sales DataFrame you have been working with has been extended to now include State information as well. In the IPython Shell, print the new sales DataFrame to inspect the data. Take note of the MultiIndex!\n",
    "\n",
    "Extracting elements from the outermost level of a MultiIndex is just like in the case of a single-level Index. You can use the `.loc[]` accessor as Dhavide demonstrated in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sales.loc[['CA', 'TX']]\n",
    "print(sales.loc[['CA', 'TX']])\n",
    "\n",
    "# Print sales['CA':'TX']\n",
    "print(sales['CA':'TX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting & sorting a MultiIndex\n",
    "In the previous exercise, the MultiIndex was created and sorted for you. Now, you're going to do this yourself! With a `MultiIndex`, you should always ensure the index is sorted. You can skip this only if you know the data is already sorted on the index fields.\n",
    "\n",
    "To get started, print the pre-loaded sales DataFrame in the IPython Shell to verify that there is no MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to be the columns ['state', 'month']: sales\n",
    "sales = sales.set_index(['state', 'month'])\n",
    "\n",
    "# Sort the MultiIndex: sales\n",
    "sales = sales.sort_index()\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.loc[]` with nonunique indexes\n",
    "As Dhavide mentioned in the video, it is always preferable to have a meaningful index that uniquely identifies each row. Even though pandas does not require unique index values in DataFrames, it works better if the index values are indeed unique. To see an example of this, you will index your sales data by `'state'` in this exercise.\n",
    "\n",
    "As always, begin by printing the sales DataFrame in the IPython Shell and inspecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the column 'state': sales\n",
    "sales = sales.set_index('state')\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Access the data from 'NY'\n",
    "print(sales.loc[\"NY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing multiple levels of a MultiIndex\n",
    "Looking up indexed data is fast and efficient. And you have already seen that lookups based on the outermost level of a MultiIndex work just like lookups on DataFrames that have a single-level Index.\n",
    "\n",
    "Looking up data based on inner levels of a MultiIndex can be a bit trickier. In this exercise, you will use your sales DataFrame to do some increasingly complex lookups.\n",
    "\n",
    "The trickiest of all these lookups are when you want to access some inner levels of the index. In this case, you need to use `slice(None)` in the slicing parameter for the outermost dimension(s) instead of the usual :, or use pd.IndexSlice. You can refer to the pandas documentation for more details. For example, in the video, Dhavide used the following code to extract rows from all Symbols for the dates Oct. 3rd through 4th inclusive:\n",
    "\n",
    "```` (python)\n",
    "stocks.loc[(slice(None), slice('2016-10-03', '2016-10-04')), :]\n",
    "````\n",
    "Pay particular attention to the tuple (slice(None), slice('2016-10-03', '2016-10-04'))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up data for NY in month 1: NY_month1\n",
    "NY_month1 = sales.loc[(\"NY\", 1), :]\n",
    "\n",
    "# Look up data for CA and TX in month 2: CA_TX_month2\n",
    "CA_TX_month2 = sales.loc[([\"CA\", \"TX\"], 2), :]\n",
    "\n",
    "# Access the inner month index and look up data for all states in month 2: all_month2\n",
    "all_month2 = sales.loc[(slice(None), slice(None)), 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 3: Rearranging and reshaping data\n",
    "### Reshaping: \n",
    "In this chapter, we will have a close look into `'pivot, stack, unstack'` and `'melt'` functions. \n",
    "![pivot](reshaping_pivot.png)\n",
    "![stack](reshaping_stack.png)\n",
    "![unstack](reshaping_unstack.png)\n",
    "![unstack0](reshaping_unstack_0.png)\n",
    "![unstack1](reshaping_unstack_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting a single variable\n",
    "Suppose you started a blog for a band, and you would like to log how many visitors you have had, and how many signed-up for your newsletter. To help design the tours later, you track where the visitors are. A DataFrame called users consisting of this information has been pre-loaded for you.\n",
    "\n",
    "Inspect users in the IPython Shell and make a note of which variable you want to use to index the rows (`'weekday'`), which variable you want to use to index the columns (`'city'`), and which variable will populate the values in the cells (`'visitors'`). Try to visualize what the result should be.\n",
    "\n",
    "For example, in the video, Dhavide used `'treatment'` to index the rows, `'gender'` to index the columns, and 'response' to populate the cells. Prior to pivoting, the DataFrame looked like this:\n",
    "\n",
    "````\n",
    "   id treatment gender  response\n",
    "0   1         A      F         5\n",
    "1   2         A      M         3\n",
    "2   3         B      F         8\n",
    "3   4         B      M         9\n",
    "````\n",
    "\n",
    "After pivoting:\n",
    "\n",
    "````\n",
    "gender     F  M\n",
    "treatment      \n",
    "A          5  3\n",
    "B          8  9\n",
    "````\n",
    "\n",
    "In this exercise, your job is to pivot users so that the focus is on 'visitors', with the columns indexed by 'city' and the rows indexed by 'weekday'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the users DataFrame: visitors_pivot\n",
    "visitors_pivot = users.pivot(index='weekday', columns='city', values='visitors')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(visitors_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting all variables\n",
    "If you do not select any particular variables, all of them will be pivoted. In this case - with the users DataFrame - both `'visitors'` and `'signups'` will be pivoted, creating hierarchical column labels.\n",
    "\n",
    "You will explore this for yourself now in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot users with signups indexed by weekday and city: signups_pivot\n",
    "signups_pivot = users.pivot(index='weekday', columns='city', values='signups')\n",
    "\n",
    "# Print signups_pivot\n",
    "print(signups_pivot)\n",
    "\n",
    "# Pivot users pivoted by both signups and visitors: pivot\n",
    "pivot = users.pivot(index='weekday', columns='city')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking & unstacking\n",
    "You are now going to practice stacking and unstacking DataFrames. The users DataFrame you have been working with in this chapter has been pre-loaded for you, this time with a MultiIndex. Explore it in the IPython Shell to see the data layout. Pay attention to the index, and notice that the index levels are `['city', 'weekday']`. So `'weekday'` - the second entry - has position 1. This position is what corresponds to the level parameter in .stack() and .unstack() calls. Alternatively, you can specify `'weekday'` as the level instead of its position.\n",
    "\n",
    "Your job in this exercise is to unstack users by `'weekday'`. You will then use .stack() on the unstacked DataFrame to see if you get back the original layout of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack users by 'weekday': byweekday\n",
    "byweekday = users.unstack(level='weekday')\n",
    "\n",
    "# Print the byweekday DataFrame\n",
    "print(byweekday)\n",
    "\n",
    "# Stack byweekday by 'weekday' and print it\n",
    "print(byweekday.stack(level='weekday'))\n",
    "\n",
    "# Unstack users by 'city': bycity\n",
    "bycity = user.unstack(level='city')\n",
    "\n",
    "# Print the bycity DataFrame\n",
    "print(bycity)\n",
    "\n",
    "# Stack bycity by 'city' and print it\n",
    "print(bycity.stack(level='city'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring the index order\n",
    "Continuing from the previous exercise, you will now use `.swaplevel(0, 1)` to flip the index levels. Note they won't be sorted. To sort them, you will have to follow up with a `.sort_index()`. You will then obtain the original DataFrame. Note that an unsorted index leads to slicing failures.\n",
    "\n",
    "To begin, print both users and bycity in the IPython Shell. The goal here is to convert bycity back to something that looks like users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack 'city' back into the index of bycity: newusers\n",
    "newusers = bycity.stack(level='city')\n",
    "\n",
    "# Swap the levels of the index of newusers: newusers\n",
    "newusers = newusers.swaplevel(0,1)\n",
    "\n",
    "# Print newusers and verify that the index is not sorted\n",
    "print(newusers)\n",
    "\n",
    "# Sort the index of newusers: newusers\n",
    "newusers = newusers.sort_index()\n",
    "\n",
    "# Print newusers and verify that the index is now sorted\n",
    "print(newusers)\n",
    "\n",
    "# Verify that the new DataFrame is equal to the original\n",
    "print(newusers.equals(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding names for readability\n",
    "You are now going to practice melting DataFrames. A DataFrame called `visitors_by_city_weekday` has been pre-loaded for you. Explore it in the IPython Shell and see that it is the users DataFrame from previous exercises with the rows indexed by `'weekday'`, columns indexed by `'city'`, and values populated with `'visitors'`.\n",
    "\n",
    "Recall from the video that the goal of melting is to restore a pivoted DataFrame to its original form, or to change it from a wide shape to a long shape. __You can explicitly specify the columns that should remain in the reshaped DataFrame with `id_vars`, and list which columns to convert into values with `value_vars`__. As demonstrated, __if you don't pass a name to the values in `pd.melt()`, you will lose the name of your variable. You can fix this by using the value_name keyword argument__.\n",
    "\n",
    "Your job in this exercise is to melt `visitors_by_city_weekday` to move the city names from the column labels to values in a single column called `'city'`. If you were to use just `pd.melt(visitors_by_city_weekday)`, you would obtain the following result:\n",
    "````\n",
    "      city value\n",
    "0  weekday   Mon\n",
    "1  weekday   Sun\n",
    "2   Austin   326\n",
    "3   Austin   139\n",
    "4   Dallas   456\n",
    "5   Dallas   237\n",
    "````\n",
    "Therefore, you have to specify the id_vars keyword argument to ensure that 'weekday' is retained in the reshaped DataFrame, and the value_name keyword argument to change the name of value to visitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index: visitors_by_city_weekday\n",
    "visitors_by_city_weekday = visitors_by_city_weekday.reset_index() \n",
    "\n",
    "# Print visitors_by_city_weekday\n",
    "print(visitors_by_city_weekday)\n",
    "\n",
    "# Melt visitors_by_city_weekday: visitors\n",
    "visitors = pd.melt(visitors_by_city_weekday, id_vars='weekday', value_name='visitors')\n",
    "\n",
    "# Print visitors\n",
    "print(visitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output](output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going from wide to long\n",
    "You can move multiple columns into a single column (making the data long and skinny) by \"melting\" multiple columns. In this exercise, you will practice doing this.\n",
    "\n",
    "The users DataFrame has been pre-loaded for you. As always, explore it in the IPython Shell and note the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt users: skinny\n",
    "skinny = pd.melt(users, id_vars=('visitors', 'signups'))\n",
    "\n",
    "# Print skinny\n",
    "print(skinny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output1](output1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt users: skinny\n",
    "skinny = pd.melt(users, id_vars=['weekday', 'city'])\n",
    "\n",
    "# Print skinny\n",
    "print(skinny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output2](output2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining key-value pairs with `melt()`\n",
    "Sometimes, all you need is some key-value pairs, and the context does not matter. If said context is in the index, you can easily obtain what you want. For example, in the users DataFrame, the visitors and signups columns lend themselves well to being represented as `key-value pairs`. So if you created a hierarchical index with `'city'` and `'weekday'` columns as the index, you can easily extract key-value pairs for the 'visitors' and 'signups' columns by melting users and specifying `col_level=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new index: users_idx\n",
    "users_idx = users.set_index(['city', 'weekday'])\n",
    "\n",
    "# Print the users_idx DataFrame\n",
    "print(users_idx)\n",
    "\n",
    "# Obtain the key-value pairs: kv_pairs\n",
    "kv_pairs = pd.melt(users_idx, col_level=0)\n",
    "\n",
    "# Print the key-value pairs\n",
    "print(kv_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output3](output3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a pivot table\n",
    "Recall from the video that a pivot table allows you to see all of your variables as a function of two other variables. In this exercise, you will use the .pivot_table() method to see how the users DataFrame entries appear when presented as functions of the `'weekday'` and `'city'` columns. That is, with the rows indexed by `'weekday'` and the columns indexed by `'city'`.\n",
    "\n",
    "Before using the pivot table, print the users DataFrame in the IPython Shell and observe the layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame with the appropriate pivot table: by_city_day\n",
    "by_city_day = users.pivot_table(index='weekday',columns='city')\n",
    "\n",
    "# Print by_city_day\n",
    "print(by_city_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using other aggregations in pivot tables\n",
    "You can also use aggregation functions within a pivot table by specifying the aggfunc parameter. In this exercise, you will practice using the `'count'` and `len` aggregation functions - which produce the same result - on the users DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df,index=[\"Manager\",\"Rep\"],values=[\"Price\"],\n",
    "               columns=[\"Product\"],aggfunc=[np.sum])\n",
    "\n",
    "# Use a pivot table to display the count of each column: count_by_weekday1\n",
    "count_by_weekday1 = pd.pivot_table(users,index='weekday',aggfunc='count')\n",
    "\n",
    "# Print count_by_weekday\n",
    "print(count_by_weekday1)\n",
    "\n",
    "# Replace 'aggfunc='count'' with 'aggfunc=len': count_by_weekday2\n",
    "count_by_weekday2 = pd.pivot_table(users,index='weekday',aggfunc=len)\n",
    "\n",
    "# Verify that the same result is obtained\n",
    "print('==========================================')\n",
    "print(count_by_weekday1.equals(count_by_weekday2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
